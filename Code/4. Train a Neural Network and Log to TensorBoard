import tensorflow as tf
import datetime

# 1. Load the MNIST dataset and preprocess it.
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Normalize pixel values to be between 0 and 1
x_train, x_test = x_train / 255.0, x_test / 255.0

# 2. Train a simple neural network model and enable TensorBoard logging.

def create_model():
    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    return model

model = create_model()

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Define the TensorBoard callback.
log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S") # Unique log directory for each run
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1) # histogram_freq adds histograms

# Train the model with the TensorBoard callback.
model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])

# 3. Launch TensorBoard and analyze loss and accuracy trends.

# --- Instructions for launching TensorBoard ---
print(f"To launch TensorBoard, open a terminal in the same directory as your Jupyter Notebook and run:")
print(f"tensorboard --logdir {log_dir}")
print("Then, open your web browser and go to the URL provided by TensorBoard (usually http://localhost:6006/).")


# --- (Optional) Display the log directory for easy copy/paste
print(f"\nTensorBoard logs are saved in: {log_dir}")
