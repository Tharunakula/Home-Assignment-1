Original Tensor:
tf.Tensor(
[[ 0.3604439   0.00934032 -1.3287013  -1.5090463   0.44090244 -0.785383  ]
 [ 0.43612105 -1.8121129  -1.2045119   0.12081417 -0.24579923 -1.1209487 ]
 [-1.1656271  -0.2576853   1.0585288   0.92992795 -1.2807412  -0.6475989 ]
 [ 1.0679907  -0.35207313 -0.18129961  0.47208884 -0.6919468   0.62299603]], shape=(4, 6), dtype=float32)
Rank before reshaping: 2
Shape before reshaping: [4 6]

Reshaped Tensor:
tf.Tensor(
[[[ 0.3604439   0.00934032 -1.3287013  -1.5090463 ]
  [ 0.44090244 -0.785383    0.43612105 -1.8121129 ]
  [-1.2045119   0.12081417 -0.24579923 -1.1209487 ]]

 [[-1.1656271  -0.2576853   1.0585288   0.92992795]
  [-1.2807412  -0.6475989   1.0679907  -0.35207313]
  [-0.18129961  0.47208884 -0.6919468   0.62299603]]], shape=(2, 3, 4), dtype=float32)
Rank after reshaping: 3
Shape after reshaping: [2 3 4]

Transposed Tensor:
tf.Tensor(
[[[ 0.3604439   0.00934032 -1.3287013  -1.5090463 ]
  [-1.1656271  -0.2576853   1.0585288   0.92992795]]

 [[ 0.44090244 -0.785383    0.43612105 -1.8121129 ]
  [-1.2807412  -0.6475989   1.0679907  -0.35207313]]

 [[-1.2045119   0.12081417 -0.24579923 -1.1209487 ]
  [-0.18129961  0.47208884 -0.6919468   0.62299603]]], shape=(3, 2, 4), dtype=float32)
Rank after transposing: 3
Shape after transposing: [3 2 4]

Result after broadcasting and addition:
tf.Tensor(
[[[ 0.9857721   0.29443568 -1.3005364  -1.7989708 ]
  [-0.54029894  0.02741006  1.0866936   0.64000344]]

 [[ 1.0662307  -0.50028765  0.46428588 -2.1020374 ]
  [-0.65541303 -0.36250356  1.0961555  -0.6419977 ]]

 [[-0.5791837   0.40590954 -0.21763441 -1.4108732 ]
  [ 0.44402856  0.7571842  -0.663782    0.3330715 ]]], shape=(3, 2, 4), dtype=float32)

Explanation of Broadcasting:

Broadcasting in TensorFlow (and NumPy) allows arithmetic operations between tensors of different shapes, 
as long as certain compatibility rules are met.  It avoids explicit data replication, making operations 
more memory and computationally efficient.

In this example, 'smaller_tensor' with shape (1, 4) is added to 'transposed_tensor' with shape (3, 2, 4).  
Broadcasting works as follows:

1. **Dimension Alignment:** TensorFlow compares the shapes of the two tensors dimension by dimension, starting from the trailing dimensions (rightmost).

2. **Compatibility Rules:** Two dimensions are compatible if:
   a) They are equal, or
   b) One of them is 1.

3. **Expansion:**  If a dimension in one tensor is 1, TensorFlow "stretches" or "copies" that dimension to match the corresponding dimension in the other tensor.  This is the "broadcasting" part.

In our case:
- (3, 2, 4) and (1, 4)

- The last dimension (4) matches.
- The second to last dimension: 2 vs 1. The 1 is broadcasted to 2.
- The first dimension: 3 vs nothing (implicitly 1). The 1 is broadcasted to 3.

So, the (1,4) tensor is effectively "expanded" to (3, 2, 4) by replicating its rows and then the element-wise addition is performed.

Broadcasting simplifies code and improves performance, but it's crucial to understand how it works to avoid unexpected results.  If shapes are not compatible for broadcasting, TensorFlow will raise an error.

